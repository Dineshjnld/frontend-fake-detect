import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.preprocessing import StandardScaler , LabelEncoder
from keras.models import Model, Sequential
from keras.layers import Dense, Activation, Flatten, BatchNormalization, Dropout

train_path = '/content/train.csv'
test_path = '/content/test.csv'

train = pd.read_csv(train_path)
test = pd.read_csv(test_path)

train.head(10)

train.tail(10)

train.iloc[:]

train.info()

x_train = train.iloc[:, :-1].values
y_train = train.iloc[:, -1].values

x_test = test.iloc[:, :-1].values
y_test = test.iloc[:, -1].values

np.save('x_train.npy', x_train)
np.save('y_train.npy', y_train)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train_sc = sc.fit_transform(x_train)
x_test_sc = sc.transform(x_test)

from sklearn.decomposition import PCA
pca = PCA(n_components=2)
x_train_sc_pca = pca.fit_transform(x_train_sc)
x_test_sc_pca = pca.transform(x_test_sc)

rfc = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)
rfc.fit(x_train_sc, y_train)
y_pred = rfc.predict(x_test_sc)
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)


import instaloader
import numpy as np

# Assuming 'sc' is the StandardScaler used during training
# Assuming 'rfc' is the trained Random Forest Classifier

# Step 1: Fetch details from Instagram profile using Instaloader

# Create an Instaloader instance
ig = instaloader.Instaloader()

# Get the username from user input
username = input("Enter Username: ")

# Fetch profile information
profile = instaloader.Profile.from_username(ig.context, username)

# Display username and related details
print("Username:", profile.username)

# Count the number of digits and words in the username
num_digits_in_username = sum(char.isdigit() for char in profile.username)
print("Number of digits in username:", num_digits_in_username)

num_words_in_username = len(profile.username.split())
print("Number of words in username:", num_words_in_username)

# Count the number of digits and words in the full name
num_digits_in_full_name = sum(char.isdigit() for char in profile.full_name)
print("Number of digits in full name:", num_digits_in_full_name)

num_words_in_full_name = len(profile.full_name.split())
print("Number of words in full name:", num_words_in_full_name)

# Display full name, number of posts, and bio
print("Full Name:", profile.full_name)
print("Number of Posts Uploads:", profile.mediacount)
print("Bio:", profile.biography)

# Check if the account has an external URL
if profile.external_url:
    print("External URL:", profile.external_url)
else:
    print("No External URL set.")

# Check if the account is private
if profile.is_private:
    print("Account is private.")
else:
    print("Account is not private.")

# Step 2: Use the fetched details as input to the machine learning model

# Get user input for a new profile
profile_data = {
    'profile_pic': 1 if profile.profile_pic_url else 0,
    'num_by_num': num_digits_in_username / num_words_in_username,
    'full_name': num_words_in_full_name,
    'num_by_char': num_digits_in_full_name / len(profile.full_name),
    'name_username': 1 if profile.full_name.lower() == profile.username.lower() else 0,
    'bio_len': len(profile.biography),
    'url': 1 if profile.external_url else 0,
    'private': 1 if profile.is_private else 0,
    'post': profile.mediacount,
    'followers': profile.followers,
    'follows': profile.followees,
}

# Convert the user input to a NumPy array
user_input = np.array([[profile_data['profile_pic'], profile_data['num_by_num'], profile_data['full_name'],
                        profile_data['num_by_char'], profile_data['name_username'], profile_data['bio_len'],
                        profile_data['url'], profile_data['private'], profile_data['post'],
                        profile_data['followers'], profile_data['follows']]])

# Standardize the user input using the same scaler used during training#
user_input_scaled = sc.transform(user_input)

# Make predictions for the user input
prediction = rfc.predict(user_input_scaled)


prob = rfc.predict_proba(user_input_scaled)


# Display the result
if prediction == 0:
    print('0: Genuine account')
else:
    print('1: Spam account')

prob_percentage = prob[:, prediction] * 100
percentage_value = prob_percentage.item()  # Extracting scalar value from the numpy array

print('Probability : {:.0f}%'.format(percentage_value))


